{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 20\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  LHR T5 BA Gold Wing worked wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  Very good service on this rout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |   Flight mainly let down by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified |   Another awful experience b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |   The service was rude, full...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  Not Verified |  LHR T5 BA Gold Wing worked wel...\n",
       "1  Not Verified |  Very good service on this rout...\n",
       "2  ✅ Trip Verified |   Flight mainly let down by ...\n",
       "3  ✅ Trip Verified |   Another awful experience b...\n",
       "4  ✅ Trip Verified |   The service was rude, full..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Verified |  LHR T5 BA Gold Wing worked wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Not Verified |  Very good service on this rout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>✅ Trip Verified |   Flight mainly let down by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>✅ Trip Verified |   Another awful experience b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>✅ Trip Verified |   The service was rude, full...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews\n",
       "0           0  Not Verified |  LHR T5 BA Gold Wing worked wel...\n",
       "1           1  Not Verified |  Very good service on this rout...\n",
       "2           2  ✅ Trip Verified |   Flight mainly let down by ...\n",
       "3           3  ✅ Trip Verified |   Another awful experience b...\n",
       "4           4  ✅ Trip Verified |   The service was rude, full..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"BA_reviews.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  LHR T5 BA Gold Wing worked wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  Very good service on this rout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |   Flight mainly let down by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified |   Another awful experience b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |   The service was rude, full...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  Not Verified |  LHR T5 BA Gold Wing worked wel...\n",
       "1  Not Verified |  Very good service on this rout...\n",
       "2  ✅ Trip Verified |   Flight mainly let down by ...\n",
       "3  ✅ Trip Verified |   Another awful experience b...\n",
       "4  ✅ Trip Verified |   The service was rude, full..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('Unnamed: 0',axis = 1 , inplace= True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews    Not Verified |  LHR T5 BA Gold Wing worked wel...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Casing \n",
    "- convert all text to lower cas so it is all treated the same\n",
    "- turn the column into a python list so it is easy to loop through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = data['reviews'].str.lower().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not verified |  lhr t5 ba gold wing worked well. pleasant check in and very fast security screening. concorde room service attentive. c gate boarding ok but nothing special for first passengers. latest ba version of first with only 8 suites with privacy doors. comfortable seat with plenty of stowage. good screen and good choice of ife. amenity kit good quality and bedding, pillows cushions and blankets all good. excellent menu and food very well presented. cabin crew could not have been more attentive and helpful without being obtrusive. on time departure and early arrival. bags delivered relatively swiftly and priority tagged bags were first off. all in all one of the best ba first flights i’ve had in many years. whilst not touching the middle eastern carriers ba first on this showing is easily the best way to cross the atlantic.',\n",
       " 'not verified |  very good service on this route ba2710 30th march. cabin crew worked hard, particularly ivka (?) who was on the go throughout the flight. everything you would expect of ba (and as it used to be!) shame the same cannot be said on our recent flight back from singapore, in business class on 11th feb ba12. miserable, unhappy and tetchy crew. too lazy to do anything except sleep! perhaps ba need to promote some of their short-haul performers, and let the others go.',\n",
       " '✅ trip verified |   flight mainly let down by a disagreeable flight attendant. no queue to check in at cape town - good. however checkin agent was unfamiliar with ba size and weight rules for sports bags so had to wait 10 minutes while phone calls were made -- annoying. lounge was good. gate service was excellent with organised queues. seat was good (the new upgraded club suite). the zip broke off the amenity kit so it was unusable -- ba cutting corners too much here. offered a cocktail service which came promptly and the drink was excellent. but no nuts! so i went off to the galley to ask for some nuts or a snack to go with it. i spoke to a male flight attendant who looked at me with utter distaste that i had the temerity to ask for nuts. the he said \"where have you come from?\". what a bizarre question. i said \"seat 8e\" to which he responded with a flick of his hand - \"go ask her, she\\'s serving you.\" i was stunned - i have not been treated that way in even the cheapest restaurants, let alone business class on a premium airline. the gentlemen concerned has no place in service or hospitality and should find a different line of work. anyway, the food was good. the ife worked fine. wifi wasn\\'t working. i managed 6.5 hours sleep and we got off the plane promptly despite being at a remote stand, requiring a bus. the luggage took quite a while to arrive. overall 7/10. would be 9/10 but for the rude staff member.',\n",
       " '✅ trip verified |   another awful experience by british airways. this flight was delayed nearly 1 hour. british airways charges an extortionate amount for their tickets but the service is bad for me.',\n",
       " '✅ trip verified |   the service was rude, full of attitude to me, the food is poorly serviced, the cabin during the flight was never cleaned in particularly the toilets.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the unkown characters and numbers in order not to spoile the text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = [r.replace('✅', '').strip() for r in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not verified |  lhr t5 ba gold wing worked well. pleasant check in and very fast security screening. concorde room service attentive. c gate boarding ok but nothing special for first passengers. latest ba version of first with only 8 suites with privacy doors. comfortable seat with plenty of stowage. good screen and good choice of ife. amenity kit good quality and bedding, pillows cushions and blankets all good. excellent menu and food very well presented. cabin crew could not have been more attentive and helpful without being obtrusive. on time departure and early arrival. bags delivered relatively swiftly and priority tagged bags were first off. all in all one of the best ba first flights i’ve had in many years. whilst not touching the middle eastern carriers ba first on this showing is easily the best way to cross the atlantic.',\n",
       " 'not verified |  very good service on this route ba2710 30th march. cabin crew worked hard, particularly ivka (?) who was on the go throughout the flight. everything you would expect of ba (and as it used to be!) shame the same cannot be said on our recent flight back from singapore, in business class on 11th feb ba12. miserable, unhappy and tetchy crew. too lazy to do anything except sleep! perhaps ba need to promote some of their short-haul performers, and let the others go.',\n",
       " 'trip verified |   flight mainly let down by a disagreeable flight attendant. no queue to check in at cape town - good. however checkin agent was unfamiliar with ba size and weight rules for sports bags so had to wait 10 minutes while phone calls were made -- annoying. lounge was good. gate service was excellent with organised queues. seat was good (the new upgraded club suite). the zip broke off the amenity kit so it was unusable -- ba cutting corners too much here. offered a cocktail service which came promptly and the drink was excellent. but no nuts! so i went off to the galley to ask for some nuts or a snack to go with it. i spoke to a male flight attendant who looked at me with utter distaste that i had the temerity to ask for nuts. the he said \"where have you come from?\". what a bizarre question. i said \"seat 8e\" to which he responded with a flick of his hand - \"go ask her, she\\'s serving you.\" i was stunned - i have not been treated that way in even the cheapest restaurants, let alone business class on a premium airline. the gentlemen concerned has no place in service or hospitality and should find a different line of work. anyway, the food was good. the ife worked fine. wifi wasn\\'t working. i managed 6.5 hours sleep and we got off the plane promptly despite being at a remote stand, requiring a bus. the luggage took quite a while to arrive. overall 7/10. would be 9/10 but for the rude staff member.',\n",
       " 'trip verified |   another awful experience by british airways. this flight was delayed nearly 1 hour. british airways charges an extortionate amount for their tickets but the service is bad for me.',\n",
       " 'trip verified |   the service was rude, full of attitude to me, the food is poorly serviced, the cabin during the flight was never cleaned in particularly the toilets.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = [re.sub(\"[.,|?()-:='~^0-9\\\\\\]\",\" \", item) for item in review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not verified    lhr t  ba gold wing worked well  pleasant check in and very fast security screening  concorde room service attentive  c gate boarding ok but nothing special for first passengers  latest ba version of first with only   suites with privacy doors  comfortable seat with plenty of stowage  good screen and good choice of ife  amenity kit good quality and bedding  pillows cushions and blankets all good  excellent menu and food very well presented  cabin crew could not have been more attentive and helpful without being obtrusive  on time departure and early arrival  bags delivered relatively swiftly and priority tagged bags were first off  all in all one of the best ba first flights i’ve had in many years  whilst not touching the middle eastern carriers ba first on this showing is easily the best way to cross the atlantic ',\n",
       " 'not verified    very good service on this route ba       th march  cabin crew worked hard  particularly ivka     who was on the go throughout the flight  everything you would expect of ba  and as it used to be!  shame the same cannot be said on our recent flight back from singapore  in business class on   th feb ba    miserable  unhappy and tetchy crew  too lazy to do anything except sleep! perhaps ba need to promote some of their short haul performers  and let the others go ',\n",
       " 'trip verified     flight mainly let down by a disagreeable flight attendant  no queue to check in at cape town   good  however checkin agent was unfamiliar with ba size and weight rules for sports bags so had to wait    minutes while phone calls were made    annoying  lounge was good  gate service was excellent with organised queues  seat was good  the new upgraded club suite   the zip broke off the amenity kit so it was unusable    ba cutting corners too much here  offered a cocktail service which came promptly and the drink was excellent  but no nuts! so i went off to the galley to ask for some nuts or a snack to go with it  i spoke to a male flight attendant who looked at me with utter distaste that i had the temerity to ask for nuts  the he said \"where have you come from \"  what a bizarre question  i said \"seat  e\" to which he responded with a flick of his hand   \"go ask her  she s serving you \" i was stunned   i have not been treated that way in even the cheapest restaurants  let alone business class on a premium airline  the gentlemen concerned has no place in service or hospitality and should find a different line of work  anyway  the food was good  the ife worked fine  wifi wasn t working  i managed     hours sleep and we got off the plane promptly despite being at a remote stand  requiring a bus  the luggage took quite a while to arrive  overall       would be      but for the rude staff member ',\n",
       " 'trip verified     another awful experience by british airways  this flight was delayed nearly   hour  british airways charges an extortionate amount for their tickets but the service is bad for me ',\n",
       " 'trip verified     the service was rude  full of attitude to me  the food is poorly serviced  the cabin during the flight was never cleaned in particularly the toilets ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 479.2 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.8/1.5 MB 644.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.8/1.5 MB 644.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.0/1.5 MB 645.1 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 645.1 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 645.1 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 621.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 621.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 621.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 516.7 kB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.8 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['not', 'verified', 'lhr', 't', 'ba', 'gold', 'wing', 'worked', 'well', 'pleasant', 'check', 'in', 'and', 'very', 'fast', 'security', 'screening', 'concorde', 'room', 'service', 'attentive', 'c', 'gate', 'boarding', 'ok', 'but', 'nothing', 'special', 'for', 'first', 'passengers', 'latest', 'ba', 'version', 'of', 'first', 'with', 'only', 'suites', 'with', 'privacy', 'doors', 'comfortable', 'seat', 'with', 'plenty', 'of', 'stowage', 'good', 'screen', 'and', 'good', 'choice', 'of', 'ife', 'amenity', 'kit', 'good', 'quality', 'and', 'bedding', 'pillows', 'cushions', 'and', 'blankets', 'all', 'good', 'excellent', 'menu', 'and', 'food', 'very', 'well', 'presented', 'cabin', 'crew', 'could', 'not', 'have', 'been', 'more', 'attentive', 'and', 'helpful', 'without', 'being', 'obtrusive', 'on', 'time', 'departure', 'and', 'early', 'arrival', 'bags', 'delivered', 'relatively', 'swiftly', 'and', 'priority', 'tagged', 'bags', 'were', 'first', 'off', 'all', 'in', 'all', 'one', 'of', 'the', 'best', 'ba', 'first', 'flights', 'i’ve', 'had', 'in', 'many', 'years', 'whilst', 'not', 'touching', 'the', 'middle', 'eastern', 'carriers', 'ba', 'first', 'on', 'this', 'showing', 'is', 'easily', 'the', 'best', 'way', 'to', 'cross', 'the', 'atlantic'], ['not', 'verified', 'very', 'good', 'service', 'on', 'this', 'route', 'ba', 'th', 'march', 'cabin', 'crew', 'worked', 'hard', 'particularly', 'ivka', 'who', 'was', 'on', 'the', 'go', 'throughout', 'the', 'flight', 'everything', 'you', 'would', 'expect', 'of', 'ba', 'and', 'as', 'it', 'used', 'to', 'be', '!', 'shame', 'the', 'same', 'can', 'not', 'be', 'said', 'on', 'our', 'recent', 'flight', 'back', 'from', 'singapore', 'in', 'business', 'class', 'on', 'th', 'feb', 'ba', 'miserable', 'unhappy', 'and', 'tetchy', 'crew', 'too', 'lazy', 'to', 'do', 'anything', 'except', 'sleep', '!', 'perhaps', 'ba', 'need', 'to', 'promote', 'some', 'of', 'their', 'short', 'haul', 'performers', 'and', 'let', 'the', 'others', 'go'], ['trip', 'verified', 'flight', 'mainly', 'let', 'down', 'by', 'a', 'disagreeable', 'flight', 'attendant', 'no', 'queue', 'to', 'check', 'in', 'at', 'cape', 'town', 'good', 'however', 'checkin', 'agent', 'was', 'unfamiliar', 'with', 'ba', 'size', 'and', 'weight', 'rules', 'for', 'sports', 'bags', 'so', 'had', 'to', 'wait', 'minutes', 'while', 'phone', 'calls', 'were', 'made', 'annoying', 'lounge', 'was', 'good', 'gate', 'service', 'was', 'excellent', 'with', 'organised', 'queues', 'seat', 'was', 'good', 'the', 'new', 'upgraded', 'club', 'suite', 'the', 'zip', 'broke', 'off', 'the', 'amenity', 'kit', 'so', 'it', 'was', 'unusable', 'ba', 'cutting', 'corners', 'too', 'much', 'here', 'offered', 'a', 'cocktail', 'service', 'which', 'came', 'promptly', 'and', 'the', 'drink', 'was', 'excellent', 'but', 'no', 'nuts', '!', 'so', 'i', 'went', 'off', 'to', 'the', 'galley', 'to', 'ask', 'for', 'some', 'nuts', 'or', 'a', 'snack', 'to', 'go', 'with', 'it', 'i', 'spoke', 'to', 'a', 'male', 'flight', 'attendant', 'who', 'looked', 'at', 'me', 'with', 'utter', 'distaste', 'that', 'i', 'had', 'the', 'temerity', 'to', 'ask', 'for', 'nuts', 'the', 'he', 'said', '``', 'where', 'have', 'you', 'come', 'from', '``', 'what', 'a', 'bizarre', 'question', 'i', 'said', '``', 'seat', 'e', \"''\", 'to', 'which', 'he', 'responded', 'with', 'a', 'flick', 'of', 'his', 'hand', '``', 'go', 'ask', 'her', 'she', 's', 'serving', 'you', '``', 'i', 'was', 'stunned', 'i', 'have', 'not', 'been', 'treated', 'that', 'way', 'in', 'even', 'the', 'cheapest', 'restaurants', 'let', 'alone', 'business', 'class', 'on', 'a', 'premium', 'airline', 'the', 'gentlemen', 'concerned', 'has', 'no', 'place', 'in', 'service', 'or', 'hospitality', 'and', 'should', 'find', 'a', 'different', 'line', 'of', 'work', 'anyway', 'the', 'food', 'was', 'good', 'the', 'ife', 'worked', 'fine', 'wifi', 'wasn', 't', 'working', 'i', 'managed', 'hours', 'sleep', 'and', 'we', 'got', 'off', 'the', 'plane', 'promptly', 'despite', 'being', 'at', 'a', 'remote', 'stand', 'requiring', 'a', 'bus', 'the', 'luggage', 'took', 'quite', 'a', 'while', 'to', 'arrive', 'overall', 'would', 'be', 'but', 'for', 'the', 'rude', 'staff', 'member'], ['trip', 'verified', 'another', 'awful', 'experience', 'by', 'british', 'airways', 'this', 'flight', 'was', 'delayed', 'nearly', 'hour', 'british', 'airways', 'charges', 'an', 'extortionate', 'amount', 'for', 'their', 'tickets', 'but', 'the', 'service', 'is', 'bad', 'for', 'me'], ['trip', 'verified', 'the', 'service', 'was', 'rude', 'full', 'of', 'attitude', 'to', 'me', 'the', 'food', 'is', 'poorly', 'serviced', 'the', 'cabin', 'during', 'the', 'flight', 'was', 'never', 'cleaned', 'in', 'particularly', 'the', 'toilets']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "review_tokens = [tokenizer.tokenize(item) for item in review]\n",
    "print(review_tokens[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK POS tagger\n",
    "Perform parts-of-speech tagging on each sentence using the NLTK POS tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     D:\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_dir = r'D:\\nltk_data'\n",
    "\n",
    "# Download the POS tagger model\n",
    "nltk.download('averaged_perceptron_tagger', download_dir=download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagger file exists: True\n"
     ]
    }
   ],
   "source": [
    "# Check if the POS tagger is available\n",
    "tagger_path = r\"D:\\nltk_data\"\n",
    "print(\"Tagger file exists:\", os.path.exists(tagger_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagger file exists: False\n"
     ]
    }
   ],
   "source": [
    "tagger_path2 = r\"D:\\nltk_data\\tagger\\averaged_perceptron_tagger\"\n",
    "print(\"Tagger file exists:\", os.path.exists(tagger_path2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     D:\\nltk_data\\taggers...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger', download_dir=r\"D:\\nltk_data\\taggers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(r\"D:\\nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagger file exists: True\n"
     ]
    }
   ],
   "source": [
    "tagger_path2 = r\"D:\\nltk_data\\taggers\\taggers\\averaged_perceptron_tagger\"\n",
    "print(\"Tagger file exists:\", os.path.exists(tagger_path2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagger file exists: True\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\DELL/nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\DELL\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTagger file exists:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(tagger_path))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Perform POS tagging on tokenized reviews\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m review_postage \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreview_tokens\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Print the first 5 POS-tagged reviews\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(review_postage[:\u001b[38;5;241m5\u001b[39m])\n",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTagger file exists:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(tagger_path))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Perform POS tagging on tokenized reviews\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m review_postage \u001b[38;5;241m=\u001b[39m [\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m review_tokens]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Print the first 5 POS-tagged reviews\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(review_postage[:\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tag\\__init__.py:168\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpos_tag\u001b[39m(tokens, tagset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    tag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tag\\__init__.py:110\u001b[0m, in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    108\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m PerceptronTagger(lang\u001b[38;5;241m=\u001b[39mlang)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43mPerceptronTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tagger\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tag\\perceptron.py:183\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[1;34m(self, load, lang)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tag\\perceptron.py:273\u001b[0m, in \u001b[0;36mPerceptronTagger.load_from_json\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# Automatically find path to the tagger if location is not specified.\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtaggers/averaged_perceptron_tagger_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(loc \u001b[38;5;241m+\u001b[39m TAGGER_JSONS[lang][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fin)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\DELL/nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\DELL\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "tagger_path = r\"D:\\nltk_data\\taggers\\taggers\\averaged_perceptron_tagger\"\n",
    "print(\"Tagger file exists:\", os.path.exists(tagger_path))\n",
    "\n",
    "# Perform POS tagging on tokenized reviews\n",
    "review_postage = [pos_tag(item) for item in review_tokens]\n",
    "\n",
    "# Print the first 5 POS-tagged reviews\n",
    "print(review_postage[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\DELL/nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\DELL\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pos_tag\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming review_tokens is already tokenized\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m review_postage \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreview_tokens\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Print the first 5 POS-tagged reviews\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(review_postage[:\u001b[38;5;241m5\u001b[39m])\n",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pos_tag\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming review_tokens is already tokenized\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m review_postage \u001b[38;5;241m=\u001b[39m [\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m review_tokens]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Print the first 5 POS-tagged reviews\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(review_postage[:\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tag\\__init__.py:168\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpos_tag\u001b[39m(tokens, tagset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    tag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tag\\__init__.py:110\u001b[0m, in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    108\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m PerceptronTagger(lang\u001b[38;5;241m=\u001b[39mlang)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43mPerceptronTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tagger\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tag\\perceptron.py:183\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[1;34m(self, load, lang)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tag\\perceptron.py:273\u001b[0m, in \u001b[0;36mPerceptronTagger.load_from_json\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# Automatically find path to the tagger if location is not specified.\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtaggers/averaged_perceptron_tagger_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(loc \u001b[38;5;241m+\u001b[39m TAGGER_JSONS[lang][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fin)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\DELL/nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\DELL\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Assuming review_tokens is already tokenized\n",
    "review_postage = [pos_tag(item) for item in review_tokens]\n",
    "\n",
    "# Print the first 5 POS-tagged reviews\n",
    "print(review_postage[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not determine format for nltk:taggers/averaged_perceptron_tagger based on its file\nextension; use the \"format\" argument to specify the format explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnltk_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Manually load the PerceptronTagger from your local path\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m tagger \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtaggers/averaged_perceptron_tagger\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Tokenize your reviews\u001b[39;00m\n\u001b[0;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m TreebankWordTokenizer()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\data.py:799\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m AUTO_FORMATS\u001b[38;5;241m.\u001b[39mget(ext)\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 799\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    800\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not determine format for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m based \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon its file\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mextension; use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument to specify the format explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m resource_url\n\u001b[0;32m    803\u001b[0m         )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m FORMATS:\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown format type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not determine format for nltk:taggers/averaged_perceptron_tagger based on its file\nextension; use the \"format\" argument to specify the format explicitly."
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "# Set the NLTK data path to include the directory where your POS tagger is located\n",
    "nltk.data.path.append(r\"D:\\nltk_data\")\n",
    "\n",
    "# Manually load the PerceptronTagger from your local path\n",
    "tagger = nltk.data.load('taggers/averaged_perceptron_tagger')\n",
    "\n",
    "# Tokenize your reviews\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "review_tokens = [tokenizer.tokenize(item) for item in review]\n",
    "\n",
    "# Perform POS tagging using the loaded tagger\n",
    "review_postage = [tagger.tag(item) for item in review_tokens]\n",
    "\n",
    "# Print the first 5 POS-tagged reviews\n",
    "print(review_postage[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\DELL/nltk_data', 'c:\\\\Program Files\\\\Python311\\\\nltk_data', 'c:\\\\Program Files\\\\Python311\\\\share\\\\nltk_data', 'c:\\\\Program Files\\\\Python311\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\DELL\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data', 'D:\\\\nltk_data', 'D:\\\\nltk_data', 'D:\\\\nltk_data', 'D:\\\\nltk_data', 'D:\\\\nltk_data', 'D:\\\\nltk_data', 'D:\\\\nltk_data']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.data.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not determine format for nltk:taggers/averaged_perceptron_tagger based on its file\nextension; use the \"format\" argument to specify the format explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Now load the POS tagger\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m tagger \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtaggers/averaged_perceptron_tagger\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\data.py:799\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m AUTO_FORMATS\u001b[38;5;241m.\u001b[39mget(ext)\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 799\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    800\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not determine format for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m based \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon its file\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mextension; use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument to specify the format explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m resource_url\n\u001b[0;32m    803\u001b[0m         )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m FORMATS:\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown format type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not determine format for nltk:taggers/averaged_perceptron_tagger based on its file\nextension; use the \"format\" argument to specify the format explicitly."
     ]
    }
   ],
   "source": [
    "# Remove duplicates from nltk data paths\n",
    "nltk.data.path = list(set(nltk.data.path))\n",
    "\n",
    "# Now load the POS tagger\n",
    "tagger = nltk.data.load('taggers/averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
